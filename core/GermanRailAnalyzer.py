import streamlit as st
import folium
from streamlit_folium import st_folium
import networkx as nx
import requests
import json
import os
import pandas as pd
import numpy as np
from folium.plugins import TimestampedGeoJson
from math import radians, cos, sin, asin, sqrt
from datetime import datetime, timedelta
import random


# ==========================================
# 1. æ•°æ®åŠ è½½å±‚ (Data Layer)
# ==========================================
class RailDataLoader:
    """
    è´Ÿè´£æ•°æ®çš„è·å–ä¸ç¼“å­˜ã€‚è§£å†³"æ¯æ¬¡è¯·æ±‚éƒ½æ…¢"çš„é—®é¢˜ã€‚
    å®ƒä¼šä¼˜å…ˆè¯»å–æœ¬åœ° JSONï¼Œä¸å­˜åœ¨æ—¶æ‰å» OpenStreetMap ä¸‹è½½ã€‚
    """

    def __init__(self, filename="german_railway_network.json"):
        self.filename = filename

    def load_or_fetch_data(self):
        if os.path.exists(self.filename):
            st.success(f"âœ… ä»æœ¬åœ°åŠ è½½æ•°æ®: {self.filename}")
            with open(self.filename, 'r', encoding='utf-8') as f:
                return json.load(f)
        else:
            st.warning(
                "âš ï¸ æœ¬åœ°æœªæ‰¾åˆ°æ•°æ®ï¼Œæ­£åœ¨ä» OpenStreetMap (Overpass API) ä¸‹è½½å¾·å›½ä¸»è¦è·¯ç½‘... è¿™å¯èƒ½éœ€è¦ 1-2 åˆ†é’Ÿï¼Œè¯·è€å¿ƒç­‰å¾…ã€‚")
            return self._fetch_from_overpass()

    def _fetch_from_overpass(self):
        """
        ä½¿ç”¨ Overpass API è·å–å¾·å›½ä¸»è¦é“è·¯å¹²çº¿ (usage=main)ã€‚
        è¿™æ ·æ—¢èƒ½æ‹¿åˆ°çœŸå®æ•°æ®ï¼Œåˆä¸ä¼šå› ä¸ºåŒ…å«æ‰€æœ‰æ”¯çº¿è€Œå¯¼è‡´æ–‡ä»¶è¿‡å¤§ã€‚
        """
        # Overpass QL æŸ¥è¯¢è¯­å¥
        # èŒƒå›´å¤§è‡´è¦†ç›–å¾·å›½ (47.2, 5.8, 55.1, 15.1)
        query = """
        [out:json][timeout:180];
        (
          way["railway"="rail"]["usage"="main"](47.2,5.8,55.1,15.1);
        );
        out geom;
        """
        url = "[http://overpass-api.de/api/interpreter](http://overpass-api.de/api/interpreter)"

        try:
            response = requests.get(url, params={'data': query})
            response.raise_for_status()
            data = response.json()

            # å°† Overpass çš„ JSON è½¬æ¢ä¸ºæ ‡å‡†çš„ GeoJSON æ ¼å¼ä»¥ä¾¿åç»­å¤„ç†
            geojson = self._convert_overpass_to_geojson(data)

            # ä¿å­˜åˆ°æœ¬åœ°ï¼Œä¸‹æ¬¡ç›´æ¥ç”¨
            with open(self.filename, 'w', encoding='utf-8') as f:
                json.dump(geojson, f)

            st.success(f"âœ… æ•°æ®ä¸‹è½½å¹¶ä¿å­˜æˆåŠŸ: {self.filename}")
            return geojson
        except Exception as e:
            st.error(f"âŒ æ•°æ®ä¸‹è½½å¤±è´¥: {e}")
            return None

    def _convert_overpass_to_geojson(self, overpass_data):
        """å°† OSM åŸå§‹æ•°æ®è½¬æ¢ä¸º GeoJSON FeatureCollection"""
        features =
        for element in overpass_data.get('elements', ):
            if element['type'] == 'way' and 'geometry' in element:
                # æå–åæ ‡ç‚¹
                coords = [[pt['lon'], pt['lat']] for pt in element['geometry']]

                feature = {
                    "type": "Feature",
                    "geometry": {
                        "type": "LineString",
                        "coordinates": coords
                    },
                    "properties": element.get('tags', {})
                }
                features.append(feature)
        return {"type": "FeatureCollection", "features": features}


# ==========================================
# 2. å›¾åˆ†æå¼•æ“ (Graph Engine)
# ==========================================
class RailGraph:
    """
    è´Ÿè´£æ„å»ºå›¾ç½‘ç»œã€å¤„ç†å»¶è¯¯æ•°æ®ä»¥åŠè®¡ç®— PageRankã€‚
    """

    def __init__(self):
        self.G = nx.DiGraph()
        self.pagerank_scores = {}

    def build_from_geojson(self, geojson_data):
        """
        è§£æ GeoJSON LineString æ„å»º NetworkX å›¾ã€‚
        èŠ‚ç‚¹ = çº¿è·¯çš„ç«¯ç‚¹ï¼ˆç®€åŒ–å¤„ç†ï¼Œç”¨äºæ‹“æ‰‘åˆ†æï¼‰
        è¾¹ = é“è·¯çº¿è·¯
        """
        self.G.clear()
        if not geojson_data:
            return

        for feature in geojson_data['features']:
            coords = feature['geometry']['coordinates']
            props = feature['properties']

            # è¿™é‡Œçš„é€»è¾‘æ˜¯å°†æ¯ä¸€æ®µé“è½¨è§†ä¸ºä¸¤ä¸ªèŠ‚ç‚¹ï¼ˆèµ·ç‚¹å’Œç»ˆç‚¹ï¼‰ä¹‹é—´çš„è¾¹
            # åœ¨çœŸå®å¤æ‚è·¯ç½‘ä¸­ï¼Œåº”è¯¥åšèŠ‚ç‚¹åˆå¹¶(Snap)ï¼Œä½†æ¼”ç¤ºç›®çš„ä¸‹ç›´æ¥å–é¦–å°¾è¶³çŸ£
            if len(coords) < 2: continue

            u = tuple(coords)  # èµ·ç‚¹åæ ‡ (lon, lat)
            v = tuple(coords[-1])  # ç»ˆç‚¹åæ ‡ (lon, lat)

            # è®¡ç®—ç‰©ç†è·ç¦» (ç®€å•æ¬§æ°è·ç¦»è¿‘ä¼¼ï¼Œæˆ–è€…ç”¨ Haversine)
            dist = self._haversine(u[1], u, v[1], v)

            # æ·»åŠ è¾¹ã€‚weight åˆå§‹ä¸º 1.0
            # path å±æ€§å­˜å‚¨å®Œæ•´çš„å‡ ä½•è·¯å¾„ï¼Œç”¨äºåŠ¨ç”»ç»˜åˆ¶
            self.G.add_edge(u, v, weight=1.0, distance=dist, path=coords, props=props)
            self.G.add_edge(v, u, weight=1.0, distance=dist, path=coords[::-1], props=props)

    def update_delays(self, delay_data_source):
        """
        æ›´æ–°å›¾çš„æƒé‡ã€‚
        ä½ å¯ä»¥åœ¨è¿™é‡Œæ¥å…¥ä½ ç°æœ‰çš„ API æ•°æ®ã€‚
        """
        # å‡è®¾ delay_data_source æ˜¯ä½  API è¿”å›çš„æ•°æ®
        # è¿™é‡Œä¸ºäº†æ¼”ç¤ºï¼Œæˆ‘ä»¬ä½¿ç”¨éšæœºæ¨¡æ‹Ÿï¼Œæˆ–è€…æ ¹æ®ä½  hackathon çš„ä¸»é¢˜ï¼š
        # "å½±å“æ›´é‡çš„çº¿è·¯é¢œè‰²æ›´æ·±" -> è¿™æ„å‘³ç€æˆ‘ä»¬éœ€è¦æé«˜å»¶è¯¯çº¿è·¯çš„æƒé‡

        # æ¨¡æ‹Ÿï¼šéšæœºé€‰æ‹©ä¸€äº›èŠ‚ç‚¹ä½œä¸ºå»¶è¯¯æº
        nodes = list(self.G.nodes())
        if not nodes: return

        # æ¨¡æ‹Ÿï¼šå‡è®¾è¿™äº›åŒºåŸŸå‘ç”Ÿå»¶è¯¯
        affected_nodes = random.sample(nodes, min(len(nodes), 20))

        for u, v, data in self.G.edges(data=True):
            # åŸºç¡€æƒé‡
            weight = 1.0

            # å¦‚æœè¾¹çš„ç«¯ç‚¹åœ¨å—å½±å“åˆ—è¡¨ä¸­ï¼Œå¢åŠ æƒé‡
            # åœ¨ PageRank ä¸­ï¼ŒæŒ‡å‘é«˜æƒé‡èŠ‚ç‚¹çš„è¾¹ä¼šæå‡è¯¥èŠ‚ç‚¹çš„é‡è¦æ€§
            if u in affected_nodes or v in affected_nodes:
                weight = 10.0  # å‡è®¾å»¶è¯¯ä¸¥é‡

            data['weight'] = weight
            # å­˜å‚¨å»¶è¯¯ä¿¡æ¯ä¾›å‰ç«¯æ˜¾ç¤º
            data['delay_status'] = "High Delay" if weight > 1 else "On Time"

    def calculate_pagerank(self):
        """
        è®¡ç®— PageRankã€‚
        """
        if len(self.G) == 0: return
        try:
            # ä½¿ç”¨ weight='weight'ï¼Œè¿™æ ·å»¶è¯¯è¶Šå¤§çš„çº¿è·¯ï¼Œå…¶è¿æ¥çš„æ¢çº½ PageRank è¶Šé«˜
            self.pagerank_scores = nx.pagerank(self.G, weight='weight', alpha=0.85)

            # å½’ä¸€åŒ–åˆ†æ•° (0-1) ä»¥ä¾¿ç»˜å›¾
            max_val = max(self.pagerank_scores.values())
            min_val = min(self.pagerank_scores.values())
            for k in self.pagerank_scores:
                self.pagerank_scores[k] = (self.pagerank_scores[k] - min_val) / (max_val - min_val + 1e-9)

        except Exception as e:
            st.error(f"PageRank è®¡ç®—é”™è¯¯: {e}")

    def _haversine(self, lat1, lon1, lat2, lon2):
        """è®¡ç®—ä¸¤ç‚¹é—´è·ç¦» (km)"""
        R = 6371
        dlat = radians(lat2 - lat1)
        dlon = radians(lon2 - lon1)
        a = sin(dlat / 2) ** 2 + cos(radians(lat1)) * cos(radians(lat2)) * sin(dlon / 2) ** 2
        c = 2 * asin(sqrt(a))
        return R * c


# ==========================================
# 3. å¯è§†åŒ–å±‚ (Visualization Layer)
# ==========================================
class MapVisualizer:
    def __init__(self, graph_manager):
        self.graph_mgr = graph_manager

    def get_color_by_pagerank(self, u, v):
        """
        æ ¹æ®è¾¹çš„ä¸¤ä¸ªç«¯ç‚¹çš„ PageRank å¹³å‡å€¼æ¥å†³å®šçº¿è·¯é¢œè‰²ã€‚
        PageRank è¶Šé«˜ -> é¢œè‰²è¶Šæ·±/è¶Šçº¢ã€‚
        """
        pr_u = self.graph_mgr.pagerank_scores.get(u, 0)
        pr_v = self.graph_mgr.pagerank_scores.get(v, 0)
        avg_pr = (pr_u + pr_v) / 2

        # é¢œè‰²æ˜ å°„é€»è¾‘
        if avg_pr > 0.7: return '#8B0000', 4  # æ·±çº¢ (ä¸¥é‡å½±å“)
        if avg_pr > 0.4: return '#FF4500', 3  # æ©™çº¢ (ä¸­ç­‰)
        if avg_pr > 0.2: return '#FFD700', 2  # é‡‘è‰² (è½»å¾®)
        return '#228B22', 1  # ç»¿è‰² (æ­£å¸¸)

    def generate_animation_geojson(self):
        """
        ç”Ÿæˆç”± TimestampedGeoJson ä½¿ç”¨çš„æ•°æ®ã€‚
        è®©ç«è½¦æ²¿ç€ LineString çš„çœŸå®è·¯å¾„ç§»åŠ¨ã€‚
        """
        features =
        current_time = datetime.now()

        # éšæœºé€‰å–ä¸€éƒ¨åˆ†çº¿è·¯ç”Ÿæˆç«è½¦
        edges = list(self.graph_mgr.G.edges(data=True))
        selected_edges = random.sample(edges, min(len(edges), 50))  # æ¼”ç¤ºç”¨ï¼Œé€‰50æ¡çº¿

        for u, v, data in selected_edges:
            path_coords = data.get('path', )
            if len(path_coords) < 2: continue

            # ç¡®å®šè¿™æ¡çº¿è·¯çš„é¢œè‰²ï¼ˆåŸºäº PageRankï¼‰
            color, _ = self.get_color_by_pagerank(u, v)

            # æ¨¡æ‹Ÿï¼šæ¯åˆ—è½¦è·‘å®Œå…¨ç¨‹éœ€è¦çš„æ—¶é—´ (ç§’)
            duration_sec = 20
            steps = len(path_coords)

            # ä¸ºè·¯å¾„ä¸Šçš„æ¯ä¸ªç‚¹åˆ†é…æ—¶é—´æˆ³
            for i in range(steps):
                coord = path_coords[i]

                # è®¡ç®—å½“å‰ç‚¹çš„æ—¶é—´åç§»
                time_offset = (i / steps) * duration_sec
                timestamp = (current_time + timedelta(seconds=time_offset)).isoformat()

                # æ„å»º GeoJSON Feature
                feature = {
                    'type': 'Feature',
                    'geometry': {
                        'type': 'Point',
                        'coordinates': coord
                    },
                    'properties': {
                        'time': timestamp,
                        'style': {'color': color},
                        'icon': 'circle',
                        'iconstyle': {
                            'fillColor': color,
                            'fillOpacity': 1,
                            'stroke': 'false',
                            'radius': 5
                        },
                        'popup': f"Train on line"
                    }
                }
                features.append(feature)

        return features

    def create_map(self):
        # åˆå§‹åŒ–åœ°å›¾ï¼Œä¸­å¿ƒå®šåœ¨å¾·å›½
        m = folium.Map(location=[51.1657, 10.4515], zoom_start=6, tiles='CartoDB dark_matter')

        # 1. ç»˜åˆ¶é™æ€çº¿è·¯å›¾ (èƒŒæ™¯)
        # é¢œè‰²æ ¹æ® PageRank åŠ¨æ€å˜åŒ–
        for u, v, data in self.graph_mgr.G.edges(data=True):
            color, weight = self.get_color_by_pagerank(u, v)
            coords = data.get('path', )
            # Folium éœ€è¦ (lat, lon)ï¼ŒGeoJSON æ˜¯ (lon, lat)ï¼Œæ³¨æ„åè½¬
            folium_coords = [[p[1], p] for p in coords]

            folium.PolyLine(
                folium_coords,
                color=color,
                weight=weight,
                opacity=0.6,
                tooltip=f"Status: {data.get('delay_status')}"
            ).add_to(m)

        # 2. ç”ŸæˆåŠ¨ç”»æ•°æ®å¹¶æ·»åŠ å›¾å±‚
        anim_data = self.generate_animation_geojson()
        if anim_data:
            TimestampedGeoJson(
                {'type': 'FeatureCollection', 'features': anim_data},
                period='PT1S',
                duration='PT1S',
                transition_time=200,
                auto_play=True,
                loop=True,
                max_speed=1,
                loop_button=True,
                date_options='HH:mm:ss',
                time_slider_drag_update=True
            ).add_to(m)

        return m


# ==========================================
# 4. ä¸»ç¨‹åº (Main Interface)
# ==========================================
def main():
    st.set_page_config(layout="wide", page_title="DB Delay Visualizer")

    st.title("ğŸš‚ å¾·å›½é“è·¯å»¶è¯¯å½±å“å¯è§†åŒ– (PageRank + Animation)")
    st.markdown("""
    è¯¥é¡¹ç›®å°†é“è·¯ç½‘ç»œè§†ä¸ºæœ‰å‘å›¾ï¼Œåˆ©ç”¨ **PageRank** ç®—æ³•è®¡ç®—å»¶è¯¯åœ¨ç½‘ç»œä¸­çš„â€œæƒé‡â€ã€‚
    *   **é¢œè‰²è¶Šæ·± (çº¢)**ï¼šè¡¨ç¤ºè¯¥è·¯æ®µåœ¨å½“å‰çš„å»¶è¯¯ç½‘ç»œä¸­æƒé‡è¶Šé«˜ï¼ˆå—å½±å“è¶Šå¤§ï¼‰ã€‚
    *   **æœ¬åœ°ç¼“å­˜ä¼˜åŒ–**ï¼šé¦–æ¬¡è¿è¡Œä¼šä¸‹è½½æ•°æ®ï¼Œä¹‹åç›´æ¥è¯»å– `german_railway_network.json`ã€‚
    """)

    # ä¾§è¾¹æ 
    with st.sidebar:
        st.header("æ§åˆ¶é¢æ¿")
        run_analysis = st.button("è¿è¡Œåˆ†æ & ç”Ÿæˆåœ°å›¾")

    if run_analysis:
        # 1. åŠ è½½æ•°æ®
        loader = RailDataLoader()
        geojson = loader.load_or_fetch_data()

        if geojson:
            # 2. æ„å»ºå›¾ & æ³¨å…¥å»¶è¯¯
            graph = RailGraph()
            with st.spinner("æ­£åœ¨æ„å»ºè·¯ç½‘æ‹“æ‰‘..."):
                graph.build_from_geojson(geojson)

            with st.spinner("æ­£åœ¨æ³¨å…¥å®æ—¶å»¶è¯¯æ•°æ® (API Simulation)..."):
                # è¿™é‡Œè°ƒç”¨ä½ çš„ API æ•°æ®æ¥å£
                graph.update_delays(None)

            with st.spinner("æ­£åœ¨è¿è¡Œ PageRank ç®—æ³•..."):
                graph.calculate_pagerank()

            # 3. æ¸²æŸ“åœ°å›¾
            viz = MapVisualizer(graph)
            m = viz.create_map()

            st.success("å¯è§†åŒ–ç”Ÿæˆå®Œæ¯•ï¼")
            st_folium(m, width="100%", height=700)

            # æ˜¾ç¤º PageRank Top æ¦œå•
            st.subheader("ğŸš¨ å½“å‰å»¶è¯¯å½±å“æœ€å¤§çš„å…³é”®èŠ‚ç‚¹ (Top Critical Nodes)")
            # ç®€å•çš„è¡¨æ ¼å±•ç¤º
            sorted_nodes = sorted(graph.pagerank_scores.items(), key=lambda x: x[1], reverse=True)[:10]
            df = pd.DataFrame(sorted_nodes, columns=)
            st.table(df)


if __name__ == "__main__":
    main()